{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcda55d",
   "metadata": {},
   "source": [
    "### 1. 简单的示例 \n",
    "\n",
    "![image](docs/stream_warn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2600e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 简单的示例\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([   \"https://ultralytics.com/images/bus.jpg\", \n",
    "                    \"https://ultralytics.com/images/zidane.jpg\"], stream=True)  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32cbe7",
   "metadata": {},
   "source": [
    "### 2. 多种输入源\n",
    "\n",
    "![image](docs/source_type.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 截屏目标检测\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Define current screenshot as source\n",
    "source = \"screen\"\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source, stream=True)  # list of Results objects\n",
    "\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 摄像头目标检测\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Open the default camera (0 is usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"错误: 无法打开摄像头\")\n",
    "    exit()\n",
    "\n",
    "print(\"摄像头已成功打开。按 'q' 键退出。\")\n",
    "window_name = \"YOLO 摄像头目标检测\"\n",
    "\n",
    "try:\n",
    "    # Loop through the camera frames\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if success:\n",
    "            # Run YOLO inference on the frame\n",
    "            results = model(frame)\n",
    "            \n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            \n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(window_name, annotated_frame)\n",
    "            \n",
    "            key = cv2.waitKey(30) & 0xFF\n",
    "            if key == ord(\"q\") or cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "        else:\n",
    "            print(\"错误: 无法读取摄像头画面\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    time.sleep(3)\n",
    "    print(\"摄像头已释放，窗口已关闭。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b2ce6",
   "metadata": {},
   "source": [
    "### 3. 推理参数\n",
    "\n",
    "![image](docs/model_predict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 推理参数分类\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference on 'bus.jpg' with arguments\n",
    "results = model.predict(\n",
    "                        # ---- 1. 基础输入与输出配置参数 -------------------------------------------------------------------\n",
    "                        source = \"https://ultralytics.com/images/bus.jpg\", \n",
    "                        save = True,                # 控制是否保存推理结果\n",
    "                        project = None,             # None  如果 save 已启用，则为保存预测输出的项目目录的名称。\n",
    "                        name = None,                # None  预测运行的名称。用于在项目文件夹中创建一个子目录，如果 save 已启用，则为保存预测输出的项目目录的名称。\n",
    "                        verbose = True,             # True  控制是否在终端中显示详细的推理日志，从而提供有关预测过程的实时反馈。\n",
    "                                                                \n",
    "                        # ---- 2. 图像 / 视频预处理参数 -------------------------------------------------------------------\n",
    "                        imgsz = 320,                # 640   定义推理的图像大小。适当的大小调整可以提高检测 准确性 和处理速度。\n",
    "                        batch = 1,                  # 1     指定推理的批处理大小（仅在源为以下情况时有效： 一个目录、视频文件，或 .txt 文件)。\n",
    "                                                    #       更大的批处理大小可以提供更高的吞吐量，从而缩短推理所需的总时间。\n",
    "                        vid_stride = 1,\t            # 1     视频输入的帧步长。允许跳过视频中的帧，以加快处理速度，但会降低时间分辨率。值为 1 时处理每一帧，值越高跳过的帧越多。\n",
    "                        stream_buffer = False,      # False 确定是否为视频流排队传入帧。\n",
    "\n",
    "                        # ---- 3. 模型推理效率优化参数 -------------------------------------------------------------------\n",
    "                        half = False,               # False 启用半精度 (FP16) 推理，这可以加快在支持的 GPU 上的模型推理速度，同时对准确性的影响极小。\n",
    "                        device = None,              # None  指定用于推理的设备（例如， cpu, cuda:0 或 0）。允许用户在 CPU、特定 GPU 或其他计算设备之间进行选择，以执行模型。\n",
    "                        stream = False,             # False 通过返回 Results 对象的生成器而不是一次将所有帧加载到内存中，从而为长视频或大量图像启用内存高效处理。\n",
    "                        compile = False,            # False 启用 PyTorch 2.x torch.compile 使用以下方式进行图形编译 backend='inductor'。\n",
    "                                                    #       接受   True → \"default\", \n",
    "                                                    #               False → 禁用，或字符串模式，\n",
    "                                                    #       例如 \"default\", \"reduce-overhead\", \"max-autotune-no-cudagraphs\"。\n",
    "                                                    #       如果不支持，则会发出警告并回退到 Eager 模式.\n",
    "\n",
    "                        # ---- 4. 检测结果筛选与后处理参数 -------------------------------------------------------------------\n",
    "                        conf = 0.5,                 # 0.25  设置检测的最小置信度阈值。 将忽略置信度低于此阈值的检测到的对象\n",
    "                        iou = 0.7,                  # 0.7   设置非极大值抑制 (NMS) 的 IoU 阈值\n",
    "                        max_det = 300,              # 300   每张图像允许的最大 detect 数量。限制模型在单次推理中可以 detect 的对象总数，防止在密集场景中产生过多输出。\n",
    "                                                    #       如果 False，旧帧会被丢弃以适应新帧（针对实时应用进行了优化）。\n",
    "                                                    #       如果 True，在缓冲区中对新帧进行排队，确保不跳过任何帧，但如果推理 FPS 低于流 FPS，则会导致延迟。\n",
    "                        agnostic_nms = False,       # False 启用类别无关的非极大值抑制 (NMS)，它合并不同类别的重叠框。在类别重叠常见的多类别 detect 场景中非常有用。\n",
    "                        classes = None,             # None  将预测结果筛选到一组类别 ID。只会返回属于指定类别的检测结果。这对于专注于多类别检测任务中的相关对象非常有用。\n",
    "                        rect = True,                # True  (专属检测任务) 为矩形检测模式\n",
    "\n",
    "                        # ---- 5. 高级功能与可视化参数 -------------------------------------------------------------------\n",
    "                        visualize = False,          # False 激活推理期间模型特征的可视化，从而深入了解模型正在“看到”的内容。这对于调试和模型解释非常有用。\n",
    "                        augment = False,            # False 启用测试时增强 (TTA) 进行预测，可能会提高检测的鲁棒性，但会降低推理速度。\n",
    "                        retina_masks = None,        # False (专属分割任务) 返回高分辨率分割掩码。返回的掩码（masks.data）\n",
    "                                                    #       如果启用，将与原始图像大小匹配。\n",
    "                                                    #       如果禁用，它们将具有推理期间使用的图像大小。\n",
    "                        embed = None,               # None  指定从中提取特征向量或 embeddings 的层。对于诸如聚类或相似性搜索之类的下游任务非常有用。\n",
    "\n",
    "                        )\n",
    "\n",
    "for result in results:\n",
    "    result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
